\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{enumitem}
\usepackage{algorithm2e}
\usepackage{hyperref}
\hypersetup{colorlinks=true}

\begin{document}
\noindent Brendan Robeson \hfill CS 7680 - Assignment 4 \hfill \today
%\noindent Brendan Robeson
%
%\noindent CS 7680 - Assignment 4
%
%\noindent \today

\medskip

\begin{description}[leftmargin=0in]
    \item [Source] N. Wang and D.-Y. Yeung, "Learning a Deep Compact Image
        Representation for Visual Tracking," in \emph{Advances in Neural
        Information Processing Systems 26} (C. J. Burges, L. Bottou, M. Welling,
        Z. Ghahramani, and K. Q. Weinberger, eds), p. 809-817, Curran
        Associates, Inc., 2013. Cited by 196.

    \item [URL]
        {\smaller\url{http://papers.nips.cc/paper/5192-learning-a-deep-compact-image-representation-for-visual-tracking}}

    \item [Problem] The authors want to track an object through video or an
        image sequence. Object tracking has use in several fields: security
        surveillance, sports video analysis, HCI, and machine automation, to
        name a few.

    \item [Assumptions] The authors do not state any assumptions.

    \item [Data Sets] The Tiny Images
        (\url{http://groups.csail.mit.edu/vision/TinyImages/}) dataset was used for
        offline training. The authors randomly samples 1 million images from the
        data set. The authors do not state where they acquired the video
        sequences used for their experiments. I found most (and many more) at
        \url{http://cvlab.hanyang.ac.kr/tracker_benchmark/datasets.html}.

    \item [Algorithm Overview] The authors' procedure is referred to as Deep
        Learning Tracker (DLT). In short, DLT uses a stacked denoising
        autoencoder (SDAE) to learn general features from a large imagery
        database. The tracking target is specified by a bounding box in the
        first frame, presumably by a user. Particles, from the particle
        filtering technique, are fed to the augmented SDAE for tracking.

        \begin{algorithm}
            \Begin(Offline Training)
            {
                \KwIn{Image Database}
                \ForEach{Database Image}
                {
                    Calculate autoencoder weights using Equation (4)\;
                }
                \KwOut{A trained SDAE}
            }
        \end{algorithm}

        \begin{algorithm}
            \Begin(Online Tracking)
            {
                \KwIn{Trained SDAE, Video or Image Sequence}
                Extract the encoder component from the SDAE\;
                Append a classification layer to the encoder\;
                \ForEach{Video/Image Frame}
                {
                    Extract particles\;
                    \ForEach{Particle}
                    {
                        Calculate particle confidence $p_i$ with the encoder\;
                    }
                }
                \KwOut{Tracked Object}
            }
        \end{algorithm}

        The SDAE is a series of denoising autoencoders (DAE). A DAE takes as
        input a data sample, $x_i$. The input is corrupted in some way to
        produce $\tilde{x}_i$; the authors chose to use Gaussian noise, but
        other techniques could be used. $\tilde{x}_i$ constitutes the first
        layer of an autoencoder with fewer hidden units than input units. The
        authors did not specify their activation function. The output of the DAE
        is $\hat{x}_i$, which should be equivalent to $x_i$.

        Equation (4) describes updating the DAE weights during training. This is
        an error minimization function, the error being the square distance
        between $x_i$ and $\hat{x}_i$. This function also takes into
        consideration the encoder and decoder weights, scaled by an input
        parameter, $\lambda$.
        
        Stacking the DAEs involves reducing the number of units in each layer of
        the encoder, and increasing them in each layer of the decoder. The
        authors chose to halve each subsequent encoder layer, until a layer has
        256 units. Then each layer of the encoder doubles the previous layer
        until the output layer has same number of units as the input layer.
        
        The online tracker uses the encoder portion of the trained SDAE. This is
        augmented with a classification layer using a sigmoid activation
        function. The classification layer outputs a scalar value, the
        confidence of the input particle representing the target.


    \item [Experiments] The authors compared their tracker to these seven:
        Multi-Task Tracking (MTT), Compressive Tracking (CT), Visual Tracking
        Decomposition (VTD), Multiple Instance Learning (MIL), L1 Tracker (L1T),
        Tracking-Learning-Detection (TLD), Incremental Visual Tracking (IVT).

        The authors reported, for each algorithm, the success rate and the
        central pixel error. The success rate is the percentage of frames for
        which the tracker is considered successful, as defined by the authors.
        The central pixel error is the Euclidean distance between the center
        pixels of the tracker's bounding box and the ground truth bounding box.
        The authors also list the frame rate of their algorithm, but not the
        other algorithms. Finally, for each test video, the authors provide a
        graph depicting the center error vs. frame number for each algorithm.

        Qualitatively, the authors provide a sample of frames from each video,
        with the trackers' bounding boxes overlaid on the frames.

    \item [Contributions] The authors note that their algorithm automatically
        learns image features, rather than requiring features extracted by a
        user. Also, the authors' algorithm can continue to learn as tracking
        progresses. Finally, the authors were able to train their algorithm
        using a large, general database; they did not require a small database
        specific to the video.

    \item [Shortcomings] The authors did not describe any shortcomings. They
        did, however, discuss the use of a convolutional neural network, instead
        of the SDAE, as a direction for future research. They also mentioned
        using a classifier more sophisticated than the linear classifier they
        employed.

    \item [Self Evaluation] This paper is more about applying a combination of
        algorithms; than developing a new, or improving an existing, algorithm.
        Their technique appears to make a slight improvement over previous
        techniques, but it's not the best technique for all the experimental
        videos. The cause, or causes, for DLT to perform worse on some of the
        videos is not immediately obvious.

    \item [Improvements] At this time, I have no ideas for directly improving
        the authors' technique. Given time to study more deep learning
        algorithms, it may be possible to propose an alternative technique.

    \item [Applications] Essentially, this is a deep learning technique applied
        to imagery which changes slightly over time. Perhaps it would work with
        other types of change. A target object in medical imaging slices, for
        example, don't so much move as they change size and shape.

    \item [Packages]

        Caffe by Berkeley Vision and Learning Center
        (\url{http://caffe.berkeleyvision.org/})

        DIGITS by NVidia (\url{https://developer.nvidia.com/digits})
\end{description}

 \end{document}
