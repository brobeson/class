\section{Tracking by Detection}

\begin{frame}
    \frametitle{Tracking can be treated as an object detection problem.}
    \begin{description}
        \item [Tracking by detection] Object detection in each frame.
        \item [Adaptive tracking by detection] Update the classifier online.
    \end{description}

    Separates sample generation from classifier updating.
\end{frame}

%\begin{frame}
%    \frametitle{So, what's wrong with the previous algorithms?}
%    \begin{enumerate}
%        \item<1-> How should samples be generated and labeled?
%
%            \uncover<2->{\alert{Most consider samples far from the target to be negative.}}
%        \item<1-> Classifier wants to determine \emph{what} an object is.
%
%            Tracker wants to determine \emph{where} an object is.
%
%            \uncover<3->{\alert{The two are not trained together. Thus, assuming highest classifier
%            output \(\Rightarrow\) location is not always true.}}
%    \end{enumerate}
%    \uncover<4->{Most trackers try to make the classifier more robust with respect to poor samples.}
%\end{frame}

%\begin{frame}
%    \frametitle{Adaptive tracking-by-detection algorithm}
%    \begin{algorithm}[H]
%        \DontPrintSemicolon
%        \KwIn{Video frame: \(f_t\)}
%            \ForEach{ROI image}
%            {
%                Calculate the GLCM \(P_u\)\;
%                Calculate energy using Equation (2)\;
%                Calculate contrast using Equation (3)\;
%                Calculate correlation using Equation (4)\;
%                Calculate entropy using Equation (5)\;
%                Calculate homogeneity using Equation (6)\;
%            }
%            \KwOut{A set of feature vectors}
%    \end{algorithm}
%\end{frame}

\begin{frame}
    \frametitle{How does one train adaptive tracking-by-detection?}
    \begin{itemize}
        \item The algorithm operates on frame \(f_t\), for \(t \in \{1, 2, ..., T\}\).
        \item The tracker estimates a bounding box position, \(\mathbf{p}\).
        \item Extract features \(\mathbf{x}_t^\mathbf{p}\) from patches within the bounding box.
        \item Train the classifier with \((\mathbf{x}, z)\)\uncover<3->{, where \(z = \pm1\).}
    \end{itemize}
    \uncover<2>{\alert{What is \(z\)?}}
\end{frame}

\begin{frame}
    \frametitle{How does one predict using adaptive tracking-by-detection?}
    \begin{itemize}
        \item The goal is to estimate a transformation \(\mathbf{y}_t \in
            \mathcal{Y}\), where \(\mathbf{p}_t = \mathbf{p}_{t-1} \circ \mathbf{y}_t\).
        \item \(\mathcal{Y}\) is the search space in the image.
        \item Typically, \(\mathcal{Y} = \left\{ (u,v) | u^2 + v^2 < r^2 \right \}\)
            \uncover<1>{\alert{\(\Leftarrow\) What does this mean?}}
        \item<2-> \(\mathbf{y}_t = \argmax\limits_{y \in \mathcal{Y}} h \left(
            \mathbf{x}_t^{\mathbf{p}_{t-1}}, \mathbf{y} \right)\)
        \item<2-> \(h(\mathbf{x})\) is a classification confidence function.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{How does one update the classifier?}

    \begin{itemize}
        \item Update the classifier after calculating \(\mathbf{p}_t\).
        \item Generate sample transformations: \(\left\{ \mathbf{y}_t^1,
            \mathbf{y}_t^2, ..., \mathbf{y}_t^n \right\}\).
        \item Generate training samples: \(\left\{
                \mathbf{x}_t^{\mathbf{p}_t \circ \mathbf{y}_t^1},
                \mathbf{x}_t^{\mathbf{p}_t \circ \mathbf{y}_t^2}, ...,
                \mathbf{x}_t^{\mathbf{p}_t \circ \mathbf{y}_t^n} \right\}\).
        \item Generate labels: \(\left\{ z_t^1, z_t^2, ..., z_t^n \right\}\).
        \item Use the samples and labels to update the classifier.
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{How does one label a transformation?}
    Use a transformation similarity function:

    \begin{equation}
        s_{\mathbf{t}_t}^o \left( \mathbf{y}_t^i, \mathbf{y}_t^j \right) =
            \frac{\left( \mathbf{p}_t \circ \mathbf{y}_t^i \right) \cap \left( \mathbf{p}_t \circ \mathbf{y}_t^j \right)}
                 {\left( \mathbf{p}_t \circ \mathbf{y}_t^i \right) \cup \left( \mathbf{p}_t \circ \mathbf{y}_t^j \right)}
    \end{equation}

    \uncover<1>{\alert{Does this look familiar?}}

    \uncover<2->{Then, use a labelling function:

    \begin{equation}
        l\left( s_{\mathbf{p}_t}\left(\mathbf{y}^0, \mathbf{y}_t^i \right) \right) =
            \begin{cases}
                +1 & s_{\mathbf{p}_t}\left(\mathbf{y}^0, \mathbf{y}_t^i \right) > \theta_u \\
                -1 & s_{\mathbf{p}_t}\left(\mathbf{y}^0, \mathbf{y}_t^i \right) < \theta_l \\
                 0 & \text{otherwise}
            \end{cases}
    \end{equation}

    \(\mathbf{y}^0\) is the identity transformation. }
\end{frame}

\begin{frame}
    \frametitle{So what's wrong with this?}

    \begin{itemize}
        \item \((\mathbf{x}, z)\) does not correlate \(\mathbf{y}\) with \(z\).
        \item Training samples all have equal weight in the classifier.
            \begin{itemize}
                \item A background sample with significant overlap: \(z = -1\).
                \item A background sample with less overlap: \(z = -1\).
                \item This leads to tracking error growing over time.
            \end{itemize}
        \item The labeller and the learner are distinct.
            \begin{itemize}
                \item Errors by the labeller are noise to the learner.
                \item Current techniques attempt to make the learner more
                    robust, but not address the cause of the noise.
            \end{itemize}
    \end{itemize}
\end{frame}
