\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}

\begin{document}
\noindent Brendan Robeson

\noindent CS 7680 - Assignment 1

\noindent \today

\medskip

\begin{enumerate}
    \item Tian et al. \cite{5688239} has 55 citations according to Google
        Scholar.

    \item The paper is available at
        http://ieeexplore.ieee.org/document/5688239/.

    \item The primary goal of the paper is to improve segmentation of brain
        tissue in MR imagery. They accomplish this by improving the EM algorithm
        frequently used in MR imagery segmentation. Segmenting MR imagery allows
        doctors to better analyze the imagery and focus on the tissue of
        concern. Manual segmentation is time consuming; subjective; and
        difficult, if not impossible, to reproduce.
        %These issues make manual
        %segmentation impractical for large neurological studies. The authors
        %point out that the traditional EM algorithm tends to over fit the
        %training data, and can become focused on local optima. These drawbacks
        %limit the accuracy of EM. The authors also state that EM is
        %deterministic, implying this is also a drawback. However, this property
        %seems to me to be an advantage.

    \item The authors make standard assumptions about their data as required by
        GMM. Brain MR imagery is composed of volume elements, or voxels. The
        authors assume that each voxel represents a single type of tissue; that
        is, a voxel will not contain a bit of tissue type 1 and a bit of tissue
        type 2. For their experiments, the authors assumed three Gaussian models
        for the EM and variational EM (VEM) algorithms.

    \item Two data sets were used for verification and experimentation. The
        first consisted of 20 low resolution brain MR images. The second set was
        17 high resolution brain MR images. Both data sets were obtained from
        The Internet Brain Segmentation Repository (IBSR). The repository's URL
        is http://www.cma.mgh.harvard.edu/ibsr/index.html.

    \item The goal of the genetic algorithm (GA) initialization process is to
        determine the best set of GMM parameters, \(\Theta\). The process starts
        with a population of parameter sets; the authors use 500 sets. Each
        initial set has parameters with random, though valid, values. GA is an
        iterative process. For each iteration, the fitness value for each
        parameter set is calculated. The set with the highest fitness is
        retained for the next iteration. All other parameter sets are combined
        to create new parameter sets. The authors refer the reader to two
        references for the combination operation: BLX-0.5 operator and a
        permutation operator. The next iteration then operates on the new
        parameter set. After a predetermined number of iterations, the parameter
        set with highest fitness score is used to initialize the VEM
        hyperparameter set, \(\Psi\). Equation (18) describes the iterative
        process for calculating \(\alpha^0\). Calculating the remaining
        parameters is described in the text, not by equations.

        The VEM algorithm is an iterative process, involving two basic steps
        for each iteration. The first step is maximize \(L(q;\Psi)\) with
        respect to \(q(\Theta)\). During this step, \(\Psi\) remains constant.
        Equation (15) is calculated for each distribution. The maximum result is
        kept for the second step, maximizing \(L(q;\Psi)\) with respect to
        \(q(Z)\). This is done by calculating the maximum value of equation
        (16). Equations (13) and (14) show how the two results are combined.
        This process iterates until the difference in \(\Psi\) from one
        iteration to the next is below an acceptable threshold. Equations (17)
        describe how to update the parameters in \(\Psi\).

    \item The authors compared their GA-VEM algorithm to standard Expectation
        Maximization (EM), Variational EM (VEM), and to Genetic Algorithm EM
        (GA-EM). The GA-EM algorithm tested was obtained from the MIXTUREGA
        software package, available at \\
        http://www.cs.tut.fi/~tohkaj/gamixture.html. In addition, the authors
        compared their segmentation to that of the software packages Statistical
        Parametric Mapping (SPM) and FMRIB Software Library (FSL). The versions
        of SPM and FSL used are not specified. SPM is available for download at
        http://www.fil.ion.ucl.ac.uk/spm/ and FLS is available at \\
        https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/.

        Quantitative measurements include voxel histograms, comparing the ground
        truth results to the calculated results. Line graphs compare the
        classification accuracies of the various techniques. The accuracy
        measurement used is Jaccard similarity coefficient. Box-and-whisker
        plots show the effect of modifying \(\beta^0\) on the accuracy of
        GA-VEM.

        Qualitative results are shown with classified MR images. Images for each
        technique, and the ground truth, are colored by tissue class and shown
        for visual comparison of the output.

    \item The authors claim that using GA overcomes the difficulty of
        initializing VEM. Their GA-VEM algorithm results in more accurate
        classification than the alternatives compared in the experiments.

    \item The only issue noted with GA-VEM by the authors is determining the
        initial value of the \(\beta^0\) hyperparameter. The authors ran a set
        of experiments with different initial values of \(\beta^0\), to evaluate
        the effect on classification accuracy. The authors made no mention of
        ideas for future improvement.

    \item The authors' technique is slightly novel; it simply combines two
        existing techniques. The complexity is higher than EM, but only by a
        constant factor. The experimental data set seems a bit small, only 37 MR
        images.

    \item The authors' current GA algorithm iterates a fixed number of times. I
        think a better algorithm would iterate until a fitness is found that is
        equal to, or greater than, a threshold fitness. I'm not entirely sure
        this is possible, though. The fitness is defined as the log of the
        probability of X given \(\Theta^{(i)}\). This would require knowing that
        there exists some parameter set with a suitably high probability for X.

    \item It seems clear that GA-VEM can be applied to any image or video
        processing tasks for which EM is used.

    \item em4gmm is a C implementation of the EM algorithm \\
        (https://github.com/juandavm/em4gmm). The OpenCV library also contains
        an EM implementation \\
        (http://docs.opencv.org/2.4/modules/ml/doc/expectation\_maximization.html).
\end{enumerate}

\bibliographystyle{IEEEtran}
\bibliography{references}
\end{document}
