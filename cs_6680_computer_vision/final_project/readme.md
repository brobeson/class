# Counting Cars in UAV Imagery

## Running the demonstration scripts

Two demonstration scripts are provided: *uav_short_demo.m* and *uav_full_demo.m*. Simply run the script as you would any Matlab script:

```matlab
>> uav_full_demo
```

The short demonstration runs in a minute or two. It will generate figures showing the results of each major step in the process, and will present a table of car count data, and a table of execution time data. The tables are also saved to the workspace directory as CSV files: *short_demo_counts.txt* and *short_demo_times.txt*.

The full demonstration takes about five hours to run. It does not generate intermediate figures, but presents the same tables upon completion. The tables are saved as *full_demo_counts.txt* and *full_demo_times.txt*.

### Prerequisites

Both scripts require the trained support vector machines available in the workspace directory. The SVMs are the files *uav_asphalt_svm.mat* and *uav_keypoitn_svm.mat*.

The demo scripts require the appropriate true count CSV file to be available in the workspace directory. The CSV files are *true_counts_small.txt* and *true_counts_full.txt*.

The demo scripts also require image files for processing. The short demo requires *small_img.png* and *small_img2.png*. The full demo requires *IMG_0085.JPG*, *IMG_0105.JPG*, and *IMG_0107.JPG*.

This table summarizes the required files:

| File | Short demo | Full demo |
|:-----|:----------:|:---------:|
| uav\_asphalt\_svm.mat   | :white\_check\_mark: | :white\_check\_mark: |
| uav\_keypoinit\_svm.mat | :white\_check\_mark: | :white\_check\_mark: |
| true\_counts\_small.txt | :white\_check\_mark: |                    |
| true\_counts\_full.txt  |                    | :white\_check\_mark: |
| small\_img.png         | :white\_check\_mark: |                    |
| small\_img2.png        | :white\_check\_mark: |                    |
| IMG\_0085.JPG          |                    | :white\_check\_mark: |
| IMG\_0105.JPG          |                    | :white\_check\_mark: |
| IMG\_0107.JPG          |                    | :white\_check\_mark: |

## Using the car counting function

The entry point for the car counting is `uav_car_counter()`. The function requires a list of image file names for analysis, and a list of file names identifying the SVMs. *Note that this function does not produce the tables generated by the demonstration scripts.* Use `help uav_car_counter` for full function help.

## Run time

Run time of the process depends on the size of the image. Test runs on an Intel Core i7 with eight cores and 16 GB of RAM yielded the following results:

| Image size (pixels) | Run time |
|:--------------------|---------:|
| 1280 x 1024         | 00:00:30 |
| 5472 x 3648         | 01:45:00 |

## Main processing steps

### Asphalt segmentation

Asphalt segmentation is done by the function `asphalt = uav_find_asphalt(img, svm, erode_se_radius, dilate_se_radius)`.

| Parameter | Description |
|:----------|:------------|
| img       | The image being processed. A uint8 RGB image. |
| svm       | The `ClassificationSVM` trained for asphalt segmentation. |
| erode\_se\_radius | The radius of a disk structuring element to use for eroding noise in the initial mask. This should be a value derived from the image resolution, eg: 30 cm / 4 cm/pixel. |
| dilate\_se\_radius | The radius of a disk structuring element to use for dilating the mask. This should be a value derived from the image resolution, eg: 300 cm / 4 cm/pixel. This is typically much larger than the erosion radius. |
| | |
| asphalt | The resulting image mask. A binary image with 1 representing asphalt. |

This function uses the SVM to generate an initial asphalt mask. Image erosion is used to eliminate noise generated by the SVM. It then dilates by a much larger amount. The authors of the paper claim a rough estimate of the roadways is all that is required, not an exact mask.

Interestingly, the asphalt SVM is returning asphalt and background areas classified opposite the training. That is, asphalt is given class -1 and background is given class 1. `uav_find_asphalt` converts all values of -1 to 0, then subtracts the mask from 1, giving the correct mask.

Correctness can be evaluated by observing the intermediate figure. It generates three plots: the mask, the masked image (showing asphalt regions), and the image covered by the inverse mask (showing non-asphalt regions). Run time is reported by the function `uav_car_counter()`.

This step is subject to the quality of the SVM training. A poorly trained SVM will generate a poor mask. It can also require multiple runs to establish suitable values for `erode_se_radius` and `dilate_se_radius`.

This function uses `predict()` from the Statistics and Machine Learning Toolbox. Also used are `imdilate()` and `imerode()`, both from the Image Processing toolbox. These are standard toolboxes available from MathWorks.

### Key point extraction

Key point extraction is done by the function `[frames, descriptors] = uav_sift(img)`.

| Parameter | Description |
|:----------|:------------|
| img         | The image being processed. A uint8 RGB image. |
| | |
| frames      | The SIFT frames [1]. This is a matrix of class double, with four rows, and one column for each frame. The rows in order are: X, Y, S, θ. |
| descriptors | The SIFT frame descriptors [1]. These are enhanced with color information as described in [2]. The descriptors are a matrix of class double, with 152 rows, and one column for each frame. Each descriptor contains standard SIFT information, and the additional color information as described in [2].

This function uses the SIFT algorith to extract key points from the input image. The key points' geometric information is returned in the `frames` output. The `descriptors` output contains the standard SIFT descriptor, appended with color information at the key points' locations in the image. This is the RGB and HSV data for the pixel. It also contains the RGB information for three image dilations and three image erosions.

Correctness can be evaluated by observing the intermediate figure. It shows the image with the key points overlaid as red dots. Run time is reported by the function `uav_car_counter()`.

SIFT is subject to tuning of some input parameters. Getting these parameters correct can require multiple runs of this function. Tuning the peak threshold parameter, as described in the paper, results in no key points being extracted. I suspect that not being able to set this parameter results in too many key points being extracted.

This function uses `vl_sift()` from the VLFeat toolbox. This toolbox can be downloaded from http://www.vlfeat.org/download.html. Installation instructions are available at http://www.vlfeat.org/install-matlab.html. Also used are `imdilate()` and `imerode()`, both from the Image Processing toolbox. This is a standard toolbox available from MathWorks.

### Key point classification

Key point classification is not given a separate function. It just uses a single Matlab function, then a straightfoward loop. It requires the key point frames and descriptors from the key point extraction step, and the trained key point classification SVM. Using the descriptors as the observations, `predict()` is used to classify them. For any key point classified as -1 (non-car), the corresponding key point frame is deleted. The descriptors are not used after this, so they are not purged as the frames are. This step results in a reduced set of key point frames.

Correctness can be evaluated by observing the intermediate figure. It shows the image with the car key points overlaid as red dots. Run time is reported by the function `uav_car_counter()`.

Like the asphalt segmentation step, this step is subject to the quality of the SVM training. An improperly trained SVM can result to too many, or too few, car key points.

This function uses `predict()` from the Statistics and Machine Learning Toolbox. This is a standard toolbox available from MathWorks.

### Key point reduction

Key point reduction involves removing car key points which are not within asphalt segments. This requires the asphalt mask from the first step, and the car key points from the previous step. For each car key point, if the point's location in the asphalt mask is 1, the point is kept; otherwise the point is rejected. The result is a further reduced set of key point frames.

Correctness can be evaluated by observing the intermediate figure. It shows the image with the car key points in asphalt overlaid as red dots. Run time is reported by the function `uav_car_counter()`.

The quality of the output is subject the quality of the asphalt mask. Any errors in generating the mask propogate to generating erroneous key point data.

This step only uses basic Matlab functionality. No external toolboxes are required.

### Key point merging

The final step is merging of key point frames, implemented in the function `[merged_keypoints, n] = uav_merge_keypoints(key_points, t_distance)`.

| Parameter | Description |
|:----------|:------------|
| key\_points       |  The set of car key points to merge. This should be a 2D matrix. Each column is a key point. Each key point consists of four rows: X, Y, S, and θ. |
| t\_distance       |  The threshold distance for merging key points. Points closer than this distance are merged. This value should be expressed in pixel units, and take into consideration the image resolution. |
| merged\_keypoints |  The set of key points remaining after the merge operation. |
| n                 | The number of key points after the merging operation is complete. |

Merging the set of key points follows this algorithm:

- Append a value _m = 1_ to each key point frame.
- Create an NxN matrix _D_, where _N_ is the number of key points.
  - Set each matrix element _ij_, for _i =/= j_, to the distance between key
     points _i_ and _j_.
  - Set the diagonal _i == j_ to the maximum system value (`realmax`).
- Set _tmin_ to the minimum value of _D_.
- While *t\_distance < tmin*
  - Determine the key points _i_ and _j_ corresponding to _tmin_.
  - Merge key points _i_ and _j_ to get key point _k_.
  - Remove key points _i_ and _j_ from the set of key point frames.
  - Add key point _k_ to the set of key point frames.
  - Remove rows and columns _i_ and _j_ from _D_.
  - Append a row and column to _D_.
  - Calculate the distance between each key point and the new key point _k_. Set
    the corresponding elements of _D_ to the distances. Set the distatnce from
    _k_ to itself to `realmax`.
  - Set _tmin_ to the minimum value of _D_.
  - Repeat the loop
- Delete all key points with _m == 1_.
- Set _n_ to the number of remaining key points.

Two key points are merged via a weighted average:

```
        (i_x)(i_m) + (j_x)(j_m)
k_x = ----------------------------
                i_m + j_m
        (i_y)(i_m) + (j_y)(j_m)
k_y = ----------------------------
                i_m + j_m
        (i_s)(i_m) + (j_s)(j_m)
k_s = ----------------------------
                i_m + j_m
        (i_θ)(i_m) + (j_θ)(j_m)
k_θ = ----------------------------
                i_m + j_m
k_m = i_m + j_m + 1
```

Correctness can be evaluated by observing the intermediate figure. It shows the image with the merged key points overlaid as red dots. Run time is reported by the function `uav_car_counter()`.

This function is subject to a single threshold distance. This doesn't consider that vehicles are rectangular, or that they can differ significantly in size (consider a sports car compared to a semi-truck).

This function only uses basic Matlab functionality. No external toolboxes are required.

## Improvements and changes

No attempts have been made to improve this process. The results from my implementation are not yet accurate. A basic software engineering principle is to "get it working first, then optimize it." I considered reducing the number of key points before classifying them. I hypothesized that this would improve performance. After seeing the run time statistics, though, it's evident that the asphalt segmentation and key point merging are the time consuming operations. The proposed change would not affect either of the steps.

The paper implies that, during the key point merging loop, _D_ should be recalcualed during each iteration. My implementation only recalculates the new information. My implementation still may require several matrix allocations; improving that aspect may significantly improve the merging performance.

## Data structures

No custom data structures were implemented for this project. The standard Matlab matrix and `ClassificationSVM` sufficed for every step.

## Issues

Training the SVMs proved to be inadequate, primarily due to my inexperience with SVMs. Given more time, I would research them further, so that I could utilize the tuning parameters discussed in the paper.

A similar problem occured using `vl_sift()`. Attempting to set the peak threshold resulted in no key points being generated. Again, with more time, I would research the SIFT algorithm more in an attempt to determine my mistake.

## Comparison with the original implementation

My implementation performs significantly worse than the authors, often producing many more false positives.

## Experimental results

### uav\_full\_demo

`uav_full_demo` processes three full-size images (5472 x 3648). `uav_short_demo` processes two smaller images (1280 x 1024). The following table summarizes the car counts:

| Image | Calculated Count | True Count | Accuracy\* |
|:------|-----------------:|-----------:|-----------:|
| IMG\_0085.JPG | 607 |  12 | 5058% |
| IMG\_0105.JPG | 487 | 118 |  412% |
| IMG\_0107.JPG | 517 |  23 | 2247% |
| small\_img.png  | 44 |  8 | 688% |
| small\_img2.png | 12 | 20 |  60% |

_Calculated Count_ shows the number of cars counted by the implementation. _True Count_ shows the actual number of cars in the image. These values were determined by manually counting the cars in the image. _Accuracy_ is the percentage of under- or over-counting. % = _Caclulated Count_ / _True Count_ \* 100. A value greater than 100 indicates an overcount, false positives. A value less than 100 indicates an undercount, false negatives. To reproduce these results, run the demo scripts.

By contrast, the authors reported these results:

| Image | Calculated Count | True Count | Accuracy\* |
|:------|-----------------:|-----------:|-----------:|
| Image Test 1 | 75 | 51 | 147% |
| Image Test 2 | 39 | 31 | 126% |
| Image Test 3 | 76 | 19 | 400% |
| Image Test 4 | 19 | 15 | 126% |
| Image Test 5 | 22 |  3 | 733% |

Note that the authors did not present their results in this manner. The provide a table showing true positives, false positives, actual count, producer's accuracy, user's accuracy, and total accuracy. I performed the math to present a table comparable to mine.

The following two tables show the run time for each major step of the process. The first shows the run times measured in seconds. The second shows the run times as a percentage of the total run time.

| Image | Asphalt | Key Point Extraction | Key Point Classification | Key Point Reduction | Key Point Merging | Total |
|:---|---:|---:|---:|---:|---:|---:|
| IMG\_0085.JPG   | 215.714269 | 16.633096 | 42.764012 | 0.00495  | 6023.729851 | 6298.846545 |
| IMG\_0105.JPG   | 214.150864 | 21.439001 | 66.669711 | 0.003411 | 5773.657325 | 6075.920521 |
| IMG\_0107.JPG   | 212.570102 | 19.241986 | 58.883241 | 0.00323  | 6163.026247 | 6453.724856 |
| small\_img.png  |  14.958742 |  1.548434 |  2.377698 | 0.002654 |    7.069838 |   25.957849 |
| small\_img2.png |  14.311444 |  1.088026 |  2.336332 | 0.00084  |    0.395015 |   18.131864 |

| Image | Asphalt | Key Point Extraction | Key Point Classification | Key Point Reduction | Key Point Merging |
|:---|---:|---:|---:|---:|---:|
| IMG\_0085.JPG   |  3 | 0 |  1 | 0 | 96 |
| IMG\_0105.JPG   |  4 | 0 |  1 | 0 | 95 |
| IMG\_0107.JPG   |  3 | 0 |  1 | 0 | 95 |
| small\_img.png  | 58 | 6 |  9 | 0 | 27 |
| small\_img2.png | 79 | 6 | 13 | 0 |  2 |

The authors did not provide run time statistics in their paper, thus my implementation cannot be compared to theirs in terms of efficiency. It's interesting to note that, for full size imagery, the execution time is dominated by the key point merging step. As the image size drops, the asphalt segmentation becomes the time bottleneck. The authors do not claim to have developed a system which can be run in real time. However, timely processing is important for many applications. These data help to identify where timing problems exist.

Simply run the demo scripts to reproduce these data.










## Training the support vector machines (SVM)

Two SVMs are required to process imagery: asphalt segmentation, and key point
classification. You can train your own SVMs, or use the two provided SVMs:
*uav\_asphalt\_svm.mat* and *uav\_keypoint\_svm.mat*. To train your own SVMs,
follow these steps:

### Training the asphalt segmentation SVM
1. Observations are the red, green, and blue pixel values.
1. Asphalt observations must be assigned to class 1.
1. Non-asphalt observations must be assigned to class -1.
1. Use this line to train the SVM: `svm = fitcsvm(double(observations), asphalt_classes);`
  1. The returned SVM must be a `ClassificationSVM`.
  1. The returned SVM must be stored in a variable named 'svm'.
1. Save the SVM to a .mat file: `save(filename, 'svm');`.

### Training the key point classification SVM
1. Observations are SIFT key point descriptors.
1. Use this line to get the descriptors: `[frames, descriptors] = uav_sift(training_img);`.
1. Car key points must be assigned to class 1.
1. Non-car key points must be assigned to class -1.

### Prerequisites

###### Matlab R2016b

The code was developed using Matlab R2016b, but it should be able to run on
earlier versions.

The VLFeat toolbox must be installed. It can be downloaded from http://www.vlfeat.org/download.html. Installation instructions are available at http://www.vlfeat.org/install-matlab.html.

###### Imagery

To run the demonstration scripts, the sample imagery must be in your workspace
directory:

- uav\_short\_demo.m
  - small\_img.png
  - small\_img2.png
- uav\_full\_demo.m
  - IMG\_0085.JPG
  - IMG\_0105.JPG
  - IMG\_0107.JPG
